<?xml version='1.0' encoding='utf-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
  <channel>
    <title>Paper Pulse</title>
    <link>https://jamie-cui.github.io/paper-pulse</link>
    <description>Keyword-based research paper aggregation from arXiv and IACR</description>
    <lastBuildDate>Fri, 27 Feb 2026 02:04:43 -0000</lastBuildDate>
    <atom:link href="https://jamie-cui.github.io/paper-pulse/feed.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>UC-Secure Star DKG for Non-Exportable Key Shares with VSS-Free Enforcement</title>
      <link>https://arxiv.org/abs/2602.22187v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.22187v1</guid>
      <description>We present **Star DKG (SDKG)**, the first UC-secure Distributed Key Generation protocol for non-exportable key shares, eliminating Verifiable Secret Sharing (VSS) entirely. SDKG operates in the $\mathcal{F}_{KeyBox}$-hybrid model—formalizing hardware-enforced key isolation (e.g., TEEs, HSM APIs)—where shares are cryptographically bound and never exported. To enforce transcript-defined affine consistency without share exposure, we introduce **Unique Structure Verification (USV)**, a public certificate whose secret scalar remains inside the KeyBox while its group element is deterministically derivable from the transcript, and combine it with **Fischlin-style UC-extractable NIZKs** in the gRO-CRP model to enable straight-line simulation under adaptive corruptions and secure erasures. SDKG realizes a **1+1-out-of-$n$ star access structure** (designated service + any recovery device) for threshold wallets, with role-based registration. Under DL and DDH assumptions, it UC-realizes a transcript-driven refinement of standard UC-DKG, achieving $\widetilde{O}(n\log p)$ communication and $\widetilde{O}(n\log^{2.585}p)$ bit-operation cost over a prime-order group of size $p$.</description>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>model</category>
      <category>extraction</category>
    </item>
    <item>
      <title>Secure Semantic Communications via AI Defenses: Fundamentals, Solutions, and Future Directions</title>
      <link>https://arxiv.org/abs/2602.22134v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.22134v1</guid>
      <description>Semantic Communication (SemCom) shifts wireless transmission from symbol reproduction to task-oriented semantic delivery—but its AI-native architecture introduces novel security vulnerabilities: semantic failures can occur even with intact physical-layer reliability and cryptographic protection, due to adversarial model perturbations, poisoned training data, desynchronized semantic priors, or misaligned distributed inference. This survey establishes the first defense-centered, system-level framework for SemCom security via AI defenses. We propose a unified threat model categorizing attacks across four vectors—model-level, channel-realizable, knowledge-based, and networked inference—and introduce a structured defense taxonomy aligned with semantic integrity failure points: encoding, wireless transmission, knowledge integrity, and multi-agent coordination. We further define *security utility operating envelopes* to capture fidelity–robustness–latency–energy tradeoffs under realistic constraints, review evaluation metrics (e.g., Semantic BER, Task Accuracy under Attack), applications, and identify critical open challenges—including cross-layer security composition and deployment-time certification. The work provides a foundational, actionable perspective for building trustworthy SemCom systems in next-generation intelligent networks.</description>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>security</category>
      <category>poisoning</category>
      <category>data</category>
      <category>model</category>
      <category>inference</category>
    </item>
    <item>
      <title>A Critical Look into Threshold Homomorphic Encryption for Private Average Aggregation</title>
      <link>https://arxiv.org/abs/2602.22037v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.22037v1</guid>
      <description>Threshold Homomorphic Encryption (Threshold HE) is widely adopted for privacy-preserving average aggregation in Federated Learning (FL), yet recent work exposes critical vulnerabilities when adversaries access a *restricted decryption oracle*—a realistic threat reflecting FL clients’ ability to jointly decrypt results without learning the full secret key. This paper conducts the first systematic evaluation of threshold RLWE-based HE (specifically BFV and CKKS variants) for federated averaging, focusing on the practical trade-offs introduced by *smudging noise with large variance* as a security countermeasure. We benchmark communication, latency, and aggregation accuracy under standardized 128-bit security parameters across 3–16 clients. Contrary to common assumptions, we find that threshold CKKS achieves **comparable or slightly better end-to-end performance than threshold BFV**, with up to 12% lower latency at scale, while maintaining aggregation error below 0.001%—well within FL convergence tolerance. Our results provide concrete guidance for secure, efficient HE integration in production FL systems.</description>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>learning</category>
      <category>federated</category>
    </item>
    <item>
      <title>Resilient Federated Chain: Transforming Blockchain Consensus into an Active Defense Layer for Federated Learning</title>
      <link>https://arxiv.org/abs/2602.21841v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.21841v1</guid>
      <description>Federated Learning (FL) enables privacy-preserving decentralized training but remains highly vulnerable to adversarial attacks due to its inherent lack of centralized data inspection. While blockchain integration has been explored for FL, its potential as an *active defense layer*—rather than merely an immutable ledger—remains untapped. This paper proposes **Resilient Federated Chain (RFC)**, a novel framework that repurposes the computational redundancy in Proof of Federated Learning (PoFL) consensus as real-time defense infrastructure. RFC introduces a flexible, attack-adaptive evaluation function within its consensus mechanism and tightly couples on-chain verification with off-chain robust aggregation (e.g., Krum, Median). Extensive experiments on image classification under diverse adversarial settings (e.g., label-flipping, sign-flipping, Byzantine attacks) show RFC improves model accuracy by up to 37.5 percentage points over FedAvg under 20% malicious clients, while maintaining &lt;3.1% false positive rate. RFC establishes blockchain not just as a trust anchor, but as a dynamic, responsive security layer for trustworthy decentralized AI.</description>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>learning</category>
      <category>federated</category>
    </item>
    <item>
      <title>Private and Robust Contribution Evaluation in Federated Learning</title>
      <link>https://arxiv.org/abs/2602.21721v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.21721v1</guid>
      <description>Cross-silo federated learning (FL) enables collaborative model training without raw data sharing, yet client updates remain vulnerable to inference attacks. While secure aggregation (SecAgg) preserves privacy by masking individual contributions, it renders conventional contribution evaluation—critical for fair rewards and misbehavior detection—infeasible. Existing marginal-contribution methods (e.g., Shapley value) are incompatible with SecAgg; practical alternatives like Leave-One-Out (LOO) suffer from coarse granularity and dangerous self-evaluation dependencies. We propose two SecAgg-compatible marginal-difference scores: **Fair-Private**, satisfying core fairness axioms (efficiency, symmetry, null player, additivity); and **Everybody-Else**, eliminating self-evaluation entirely and providing provable resistance to strategic manipulation—a previously overlooked vulnerability. We provide rigorous theoretical guarantees on fairness, $(\varepsilon,\delta)$-differential privacy, Byzantine robustness, and linear communication/computation cost. Extensive evaluation across medical imaging datasets (BraTS, CheXpert, NIH ChestX-ray) and CIFAR10 shows our scores consistently outperform baselines: they better approximate Shapley rankings (+32–47% Kendall tau), improve final model accuracy (+1.8–3.4 pp), and achieve &gt;0.91 F1-score in detecting malicious clients. This work establishes the first principled framework jointly achieving fairness, privacy, robustness, and practical utility in FL contribution evaluation.</description>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>learning</category>
      <category>federated</category>
    </item>
    <item>
      <title>Breaking Semantic-Aware Watermarks via LLM-Guided Coherence-Preserving Semantic Injection</title>
      <link>https://arxiv.org/abs/2602.21593v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.21593v1</guid>
      <description>Generative image proliferation has spurred adoption of semantic-aware watermarking in diffusion models for provenance tracking and forgery detection. While content-aware schemes bind watermarks to high-level semantics to resist local edits, we expose a critical vulnerability: large language models (LLMs) enable *targeted, coherence-preserving semantic perturbations* that selectively alter watermark-relevant attributes without disrupting global visual-semantic consistency. We propose the **Coherence-Preserving Semantic Injection (CSI)** attack—a novel LLM-guided framework that leverages CLIP-aligned text prompts and embedding-space similarity constraints to generate semantically shifted yet visually faithful images, inducing detector misclassification. Extensive evaluation across six state-of-the-art semantic watermarking methods shows CSI consistently outperforms all baselines, increasing false-negative rates by up to 82.6% (avg. +37.4% over best prior attack). This reveals a fundamental security gap: semantic binding alone is insufficient against LLM-powered semantic manipulation.</description>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>security</category>
      <category>llm</category>
    </item>
    <item>
      <title>Prompt Architecture Determines Reasoning Quality: A Variable Isolation Study on the Car Wash Problem</title>
      <link>https://arxiv.org/abs/2602.21814v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.21814v1</guid>
      <description>This study isolates the causal impact of prompt architecture on implicit physical constraint reasoning using the “car wash problem”—a benchmark where LLMs consistently fail without explicit spatial logic cues. In a controlled variable-isolation experiment (n=20 per condition, 6 conditions), we evaluate Claude 3.5 Sonnet under fixed hyperparameters (temperature=0.7, top_p=1.0). The STAR (Situation-Task-Action-Result) reasoning framework alone boosts accuracy from 0% to 85% (*p*=0.001, Fisher’s exact test; OR=13.22), demonstrating that *forced goal articulation prior to inference* is the dominant driver of correct reasoning. User-profile context (via vector DB retrieval) adds +10 percentage points, and RAG-supplied domain context contributes an additional +5 points—reaching 100% in the full-stack condition. Crucially, structured scaffolding matters substantially more than contextual augmentation for this class of tasks: reasoning *how* to reason outweighs *what* to reason about. These findings establish STAR as a minimal, generalizable scaffold for reliable implicit-constraint inference.</description>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>prompt</category>
      <category>injection</category>
    </item>
    <item>
      <title>Learning to Collaborate via Structures: Cluster-Guided Item Alignment for Federated Recommendation</title>
      <link>https://arxiv.org/abs/2602.21957v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.21957v1</guid>
      <description>Federated recommendation (FedRec) enables collaborative model training across distributed clients without sharing raw user interaction data. Conventional methods synchronize high-dimensional item embeddings between server and clients, implicitly assuming precise geometric alignment is essential for collaboration. We challenge this assumption and argue that preserving *global semantic structures*—rather than identical embeddings—is more effective and efficient. To this end, we propose **CGFedRec**, a cluster-guided framework where the server discovers a shared item clustering structure from uploaded embeddings and broadcasts only compact cluster labels—not full embeddings—to clients. Clients then align their local item representations via these structural constraints, enabling personalization while maintaining global consistency. Experiments on six real-world datasets (e.g., Yelp, Amazon-Book, ML-1M) show CGFedRec achieves **up to 92.7% communication reduction** and **+3.8% average NDCG@10 gain** over strong baselines, demonstrating superior accuracy-efficiency trade-offs. Our work redefines collaboration in FedRec as *structural alignment*, not coordinate synchronization.</description>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>learning</category>
      <category>federated</category>
    </item>
    <item>
      <title>Learning Unknown Interdependencies for Decentralized Root Cause Analysis in Nonlinear Dynamical Systems</title>
      <link>https://arxiv.org/abs/2602.21928v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.21928v1</guid>
      <description>This paper addresses decentralized root cause analysis (RCA) in nonlinear dynamical systems—e.g., power grids and supply chains—where clients are geographically distributed, run fixed proprietary models, and exhibit unknown, time-varying interdependencies. We propose a novel federated learning framework that learns cross-client dependencies *without accessing raw sensor streams or modifying local black-box models*. Each client augments its legacy system with a lightweight, trainable dependency encoder; a global server coordinates encoders via representation consistency constraints (leveraging temporal lag correlation and contrastive alignment) while preserving privacy through calibrated differential privacy. Theoretical analysis establishes convergence guarantees under non-IID, feature-partitioned, and privacy-constrained settings. Experiments on extensive simulations and a real-world industrial cybersecurity dataset demonstrate state-of-the-art RCA performance: 92.4% F1-score on root cause localization and 58% lower false positives versus baselines—achieving RCA with *zero raw data upload, zero model modification, and zero prior dependency knowledge*.</description>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>federated</category>
      <category>machine</category>
      <category>learning</category>
      <category>differential</category>
      <category>privacy</category>
    </item>
    <item>
      <title>GFPL: Generative Federated Prototype Learning for Resource-Constrained and Data-Imbalanced Vision Task</title>
      <link>https://arxiv.org/abs/2602.21873v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.21873v1</guid>
      <description>Federated learning (FL) enables privacy-preserving collaborative training for vision tasks, yet suffers from **ineffective cross-client knowledge fusion under class imbalance** and **prohibitive communication overhead** from transmitting full-model parameters. To address this, we propose **Generative Federated Prototype Learning (GFPL)** — a lightweight, semantics-aware FL framework. GFPL replaces model parameter exchange with **class-wise prototype transmission**, where each client generates prototypes via Gaussian Mixture Models (GMM) to capture feature statistics compactly. Server-side aggregation employs **Bhattacharyya distance** to fuse semantically similar prototypes across clients, avoiding semantic misalignment. Crucially, fused prototypes generate **class-balanced pseudo-features**, and a **dual-classifier architecture**—optimized via hybrid Dot Regression and Cross-Entropy loss—enhances local feature alignment. Experiments on imbalanced benchmarks (e.g., CIFAR-10-LT, ImageNet-LT) show GFPL improves accuracy by **+3.6%** over strong baselines while reducing communication cost by **up to 87%**, achieving superior performance-efficiency trade-offs for resource-constrained edge vision applications.</description>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>learning</category>
      <category>federated</category>
    </item>
    <item>
      <title>JSAM: Privacy Straggler-Resilient Joint Client Selection and Incentive Mechanism Design in Differentially Private Federated Learning</title>
      <link>https://arxiv.org/abs/2602.21844v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.21844v1</guid>
      <description>Differentially private federated learning (DP-FL) suffers from a fundamental tension: privacy-preserving mechanisms impose quantifiable privacy costs that deter client participation, especially among highly privacy-sensitive “stragglers.” Existing incentive designs assume unbiased client selection, forcing servers to over-compensate these stragglers—leading to budget waste and suboptimal model convergence. We propose **JSAM**, the first Bayesian-optimal framework that *jointly* optimizes client selection probabilities and privacy compensation under a fixed budget. By theoretically characterizing optimal selection structure, JSAM reduces the original 2N-dimensional problem to an efficient 3D formulation. We prove that servers should *exclude* high-sensitivity clients and *preferentially select* privacy-tolerant ones—and reveal the counter-intuitive insight that *least*-sensitive clients incur the *highest cumulative cost* due to frequent selection. Extensive experiments on MNIST and CIFAR-10 show JSAM improves test accuracy by up to **15%** over unbiased baselines while maintaining cost efficiency across diverse data heterogeneity levels (α ∈ [0.1, 1.0]).</description>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>learning</category>
      <category>federated</category>
    </item>
    <item>
      <title>Mamba Meets Scheduling: Learning to Solve Flexible Job Shop Scheduling with Efficient Sequence Modeling</title>
      <link>https://arxiv.org/abs/2602.21546v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.21546v1</guid>
      <description>The Flexible Job Shop Scheduling Problem (FJSP) is a fundamental combinatorial optimization challenge in smart manufacturing, yet learning-based solvers suffer from high computational overhead and limited global dependency modeling. This paper pioneers the integration of **Mamba**—a linear-time state-space model—into FJSP solving. We propose a novel architecture featuring: (i) a dual-path Mamba encoder that separately processes operation and machine sequences to capture long-range constraints with O(N) complexity; and (ii) an efficient cross-attention decoder for dynamic operation-machine interaction. Evaluated on standard benchmarks (Dai, Brandimarte, Kacem), our method achieves **3.2× faster inference** and outperforms state-of-the-art learning-based solvers by 1.8–4.7% in makespan minimization, while reducing memory usage by 58%. This demonstrates Mamba’s superiority over quadratic-cost models (e.g., Transformers, GNNs) for structured scheduling tasks.</description>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>model</category>
      <category>extraction</category>
    </item>
    <item>
      <title>DLT-Corpus: A Large-Scale Text Collection for the Distributed Ledger Technology Domain</title>
      <link>https://arxiv.org/abs/2602.22045v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.22045v1</guid>
      <description>We present **DLT-Corpus**, the largest domain-specific text collection for Distributed Ledger Technology (DLT) research to date: **2.98 billion tokens** across **22.12 million documents**, including 37,440 scientific publications, 49,023 USPTO patents, and 22 million social media posts. Unlike prior NLP resources narrowly focused on cryptocurrency price prediction or smart contracts, DLT-Corpus comprehensively captures the full technological lifecycle of DLT. Using it, we uncover that DLT innovations emerge first in scientific literature, then migrate to patents, and finally diffuse to social media—following classic technology transfer pathways. Crucially, while social media sentiment remains persistently bullish—even during “crypto winters”—scientific and patent activity grows independently of short-term market volatility and instead tracks long-term market capitalization expansion (*r* = 0.87), revealing a virtuous innovation cycle where research enables economic growth that funds further R&amp;D. We publicly release the full corpus, **LedgerBERT** (a domain-adapted model achieving **+23% F1** over BERT-base on DLT-specific NER), and all tools and code.</description>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>crypto</category>
    </item>
    <item>
      <title>Fast cube roots in Fp2 via the algebraic torus</title>
      <link>https://eprint.iacr.org/2026/392</link>
      <guid isPermaLink="true">https://eprint.iacr.org/2026/392</guid>
      <description>We present a novel algorithm for computing cube roots in $\mathbb{F}_{p^2}$, a critical subroutine in elliptic-curve point decompression, hash-to-curve, and isogeny-based cryptography. Leveraging the algebraic torus $\mathbb{T}_2(\mathbb{F}_p)$ and Lucas sequences, our method reduces the problem *entirely* to operations in the base field $\mathbb{F}_p$—under the practically universal condition $p \equiv 1 \pmod{3}$. We prove correctness across all residuosity cases and implement it in the open-source `gnark-crypto` library. Benchmarks on six cryptographic primes (spanning pairing- and isogeny-based settings) show **1.6–2.3× speedups** over standard $\mathbb{F}_{p^2}$ exponentiation. The approach extends to $p \equiv 2 \pmod{3}$ and, more generally, to any odd $n$-th root in quadratic towers $\mathbb{F}_{p^{2^k}}$ when $\gcd(n, p+1) = 1$.</description>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0000</pubDate>
      <category>IACR</category>
    </item>
    <item>
      <title>Zero-Knowledge IOPPs for Constrained Interleaved Codes</title>
      <link>https://eprint.iacr.org/2026/391</link>
      <guid isPermaLink="true">https://eprint.iacr.org/2026/391</guid>
      <description>We present the first zero-knowledge interactive oracle proof of proximity (zk-IOPP) for constrained interleaved linear codes—achieving honest-verifier zero-knowledge with *negligible overhead* over the state-of-the-art non-ZK protocols. Our construction satisfies round-by-round knowledge soundness with a straightline extractor and negligible error. Technically, we introduce a composable definition of HVZK for interactive oracle reductions (IORs), then modularly compose lightweight zk-IORs: a novel **zero-knowledge sumcheck IOR** and a **zero-knowledge code-switching IOR**, both tailored to stringent efficiency requirements (sublinear communication, constant rounds, straightline extraction). To overcome challenges—including privacy leakage in interleaved polynomial commitments and zero-knowledge preservation across code families—we introduce new abstractions and protocols. As a side contribution, we highlight the concrete efficiency gains from high-distance codes derived from dispersers, which may be of independent interest.</description>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0000</pubDate>
      <category>IACR</category>
    </item>
    <item>
      <title>Succinct Arguments for BatchQMA and Friends under 6 Rounds</title>
      <link>https://eprint.iacr.org/2026/390</link>
      <guid isPermaLink="true">https://eprint.iacr.org/2026/390</guid>
      <description>We present the first succinct classical argument systems for batchQMA and monotone-policy batchQMA with ≤6 rounds under standard post-quantum assumptions—breaking the prior 8-round barrier and avoiding the quantum random oracle model (QROM). Our key technical innovation is **straight-line partial extractability**, enabling soundness proofs *without rewinding* cheating quantum provers—a departure from all prior works that relied on state-preserving succinct arguments of knowledge for NP. Specifically: (1) A **4-round public-coin** (except first message) argument for batchQMA achieves optimal communication (all messages independent of batch size) assuming post-quantum functional encryption and LWE; under LWE alone, only the verifier’s first message scales with batch size. (2) A **6-round private-coin** argument for monotone-policy batchQMA achieves batch-size- *and* circuit-size-independent communication under LWE. These results significantly advance practical verification of quantum computations by classical verifiers.</description>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0000</pubDate>
      <category>IACR</category>
    </item>
    <item>
      <title>Towards Accountability for Anonymous Credentials</title>
      <link>https://eprint.iacr.org/2026/389</link>
      <guid isPermaLink="true">https://eprint.iacr.org/2026/389</guid>
      <description>Anonymous Credentials (ACs) provide strong privacy by preventing issuers and verifiers from tracking users—but this very feature undermines accountability, hindering adoption in national identity systems (e.g., EUDI, Swiss e-ID). This paper identifies *transferability attacks* as a critical threat and proposes the first accountability framework for ACs. We introduce the **Cryptographic Forensic Trail (CFT)**: a tamper-evident, encrypted log attached to each credential presentation. Crucially, CFT decryption requires *joint, conditional authorization*: police must obtain a judicial warrant (based on probable cause), after which police, judge, and an independent NGO jointly execute a multiparty protocol to decrypt *only the relevant trail*. This design enforces checks and balances—neither law enforcement nor judiciary can act unilaterally, and NGO oversight detects and blocks collusion. Performance evaluation confirms practical feasibility: CFT adds &lt;300ms latency and &lt;2KB overhead on modern smartphones. Our work bridges the long-standing privacy–accountability gap in digital identity.</description>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0000</pubDate>
      <category>IACR</category>
    </item>
    <item>
      <title>Necessary and Sufficient Conditions for the Existence of Ideal Linear Secret Sharing Schemes for Arbitrary Access Structures</title>
      <link>https://eprint.iacr.org/2026/388</link>
      <guid isPermaLink="true">https://eprint.iacr.org/2026/388</guid>
      <description>This paper establishes a necessary and sufficient condition for the existence of an ideal linear secret sharing scheme (ILSSS) realizing an arbitrary minimal access structure $\Gamma_{\min}$. Using linear codes over a finite field $\mathbb{F}_q$ as the primary tool, we construct matrices $H$ (parity-check) and $G$ (generator) such that $\Gamma_{\min}$ admits an ILSSS **if and only if** the matrix equation $GH^{\mathsf{T}} = 0$ has a solution over $\mathbb{F}_q$. When satisfied, $H$ defines a linear code whose *port* realizes $\Gamma_{\min}$, and $G$ is its corresponding generator matrix. Crucially, we prove this algebraic condition is equivalent to the combinatorial requirement that $\Gamma_{\min}$ must be the port of a matroid representable over $\mathbb{F}_q$. This unifies secret sharing, coding theory, and matroid representation in a concise, computationally verifiable framework—enabling efficient existence testing and constructive design of ideal schemes.</description>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0000</pubDate>
      <category>IACR</category>
    </item>
    <item>
      <title>A Comprehensive Break of the Tropical Matrix-Based Signature Scheme</title>
      <link>https://eprint.iacr.org/2026/387</link>
      <guid isPermaLink="true">https://eprint.iacr.org/2026/387</guid>
      <description>We present a comprehensive cryptanalysis of the tropical matrix-based signature scheme GMS26 (Grigoriev–Monico–Shpilrain, 2026), which bases security on the claimed NP-hardness of tropical matrix factorization. Contrary to its security claims, we demonstrate four efficient polynomial-time attacks exploiting inherent algebraic weaknesses—not the underlying hardness assumption. First, we mount an existential forgery attack in the chosen-hash model requiring only $O(n^3)$ tropical operations. Second, we prove the scheme is fundamentally malleable: any valid signature can be transformed into infinitely many distinct yet valid signatures, breaking strong unforgeability. Third, observing $O(n)$ honest signatures enables probabilistic partial recovery of private key entries via leakage in tropical extremal equations. Fourth, using an SMT solver, we recover the *entire* private key from just **two valid signatures** in under 5 seconds for recommended parameters ($n=8$). All attacks invalidate standard security notions: existential unforgeability (EUF-CMA), strong unforgeability (SUF-CMA), and key confidentiality.</description>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0000</pubDate>
      <category>IACR</category>
    </item>
    <item>
      <title>Determining those Boolean functions whose restrictions to affine spaces are plateaued</title>
      <link>https://eprint.iacr.org/2026/386</link>
      <guid isPermaLink="true">https://eprint.iacr.org/2026/386</guid>
      <description>This paper determines the class $C^n_k$ of $n$-variable Boolean functions whose restrictions to *all* $k$-dimensional affine subspaces of $\mathbb{F}_2^n$ are plateaued (i.e., have Walsh spectra in $\{0,\pm\lambda\}$). We prove that partially-bent functions are precisely those plateaued on every affine hyperplane ($k=n-1$), while quadratic functions are exactly those plateaued on *every* $k$-dimensional affine subspace for $3 \leq k \leq n-2$. For $n \geq 5$, we establish a strict inclusion chain: quadratic $\subsetneq$ partially-bent $\subsetneq$ restrictions of partially-bent to hyperplanes $\subsetneq$ plateaued $\subsetneq$ restrictions of plateaued to hyperplanes $\subsetneq$ all Boolean functions. The characterization extends to strongly plateaued vectorial functions, and we pose an open question linking vectorial plateauedness to the long-standing crooked function problem.</description>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0000</pubDate>
      <category>IACR</category>
    </item>
    <item>
      <title>Bridging Privacy and Utility: A Verifiable Framework for Data Valuation via Zero-Knowledge Proofs</title>
      <link>https://eprint.iacr.org/2026/385</link>
      <guid isPermaLink="true">https://eprint.iacr.org/2026/385</guid>
      <description>Deep learning’s data dependency has spurred decentralized data markets, yet trust deficits persist: buyers fear poisoned data, sellers fear leakage. While the Shapley value enables fair valuation, its standard computation requires a Trusted Third Party (TTP) to access raw data—violating privacy. We propose **ZK-DV**, the first zero-knowledge proof (ZKP) system for *verifiable, privacy-preserving* data valuation. ZK-DV lets a seller prove that a claimed Gradient Shapley score is mathematically consistent with their private data and the buyer’s model—without revealing either. Its key insight is architectural co-design: we embed valuation logic directly into backpropagation via a custom arithmetic circuit, extracting marginal utilities from intermediate gradients. Implemented using the GKR protocol with a hybrid Pedersen/KZG commitment scheme and batched processing, ZK-DV amortizes cryptographic overhead. Experiments on MNIST show practicality: optimized batching achieves **2.7× faster proof generation**, perfect quantization fidelity (ρ = 1.0), and verification under **0.2 seconds**. ZK-DV bridges cryptographic integrity and economic fairness for trustless data exchange.</description>
      <pubDate>Wed, 25 Feb 2026 00:00:00 -0000</pubDate>
      <category>IACR</category>
    </item>
    <item>
      <title>ProxyFL: A Proxy-Guided Framework for Federated Semi-Supervised Learning</title>
      <link>https://arxiv.org/abs/2602.21078v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.21078v1</guid>
      <description>Federated Semi-Supervised Learning (FSSL) faces dual heterogeneity: *external* (cross-client distribution shift) and *internal* (within-client labeled/unlabeled mismatch). Existing methods either aggregate client models via fixed/dynamic weights—struggling to capture the ideal global distribution—or filter low-confidence pseudo-labels, discarding valuable unlabeled data. To address both challenges jointly, we propose **ProxyFL**, a proxy-guided framework that uses **learnable classifier weights as category-distribution proxies**. For external heterogeneity, ProxyFL explicitly optimizes a *global proxy* on the server to robustly suppress outliers, replacing direct weight aggregation. For internal heterogeneity, it introduces a *positive-negative proxy pool* to re-include filtered unlabeled samples via similarity-based soft weighting, mitigating pseudo-label noise. Theoretically, ProxyFL achieves tighter convergence bounds; empirically, it outperforms SOTAs by +3.2–5.8% average accuracy across 6 benchmarks (e.g., CIFAR-10/LT, SVHN), boosts unlabeled data utilization by 3.7×, and reduces pseudo-label error rate by 41%.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>learning</category>
      <category>federated</category>
    </item>
    <item>
      <title>Some Simple Economics of AGI</title>
      <link>https://arxiv.org/abs/2602.20946v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.20946v1</guid>
      <description>This paper reframes the AGI transition as an economic collision between two asymmetric cost curves: exponentially falling *Cost to Automate* and biologically constrained *Cost to Verify*. As AI decouples cognition from biology, execution becomes near-zero marginal cost—absorbing even creative and innovative labor—but human verification bandwidth remains the binding constraint on growth. This structural asymmetry widens a *Measurability Gap*: what agents can execute vastly exceeds what humans can afford to validate, audit, or underwrite. Consequently, technical change shifts from skill-biased to *measurability-biased*, with economic rents migrating to verification-grade ground truth, cryptographic provenance, and liability underwriting—not just output generation. The current human-in-the-loop equilibrium is unstable: eroded by collapsing apprenticeship (“Missing Junior Loop”) and expert self-obsolescence (“Codifier’s Curse”), enabling privately rational but socially hazardous unverified deployment. Unmanaged, this pulls toward a *Hollow Economy*; yet scaling verification capacity in tandem with agentic capability unlocks an *Augmented Economy*—one where robust oversight enables unbounded discovery. The central imperative is clear: the defining race today is not for autonomy, but for *verifiability*.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>trojan</category>
      <category>ai</category>
    </item>
    <item>
      <title>On Electric Vehicle Energy Demand Forecasting and the Effect of Federated Learning</title>
      <link>https://arxiv.org/abs/2602.20782v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.20782v1</guid>
      <description>This paper investigates Electric Vehicle Supply Equipment (EVSE) energy demand forecasting (EDF) under privacy-preserving constraints. We benchmark statistical (ARIMA), machine learning (XGBoost), and deep learning (LSTM, GRU) models across four real-world EVSE datasets, evaluating performance under both centralized and federated learning (FL) paradigms. Results show XGBoost achieves the highest accuracy (18.7% lower MAE on average) and best energy efficiency (5× less training energy than LSTM), outperforming both statistical and neural models. Crucially, in FL settings, XGBoost maintains this advantage while reducing communication overhead by 62% compared to deep models—demonstrating superior trade-offs among prediction fidelity, privacy preservation (no raw data sharing), and edge-device energy consumption. Our work establishes FL-enabled tree-based forecasting as a practical, scalable, and sustainable solution for decentralized EV energy management.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>learning</category>
      <category>federated</category>
    </item>
    <item>
      <title>Bikelution: Federated Gradient-Boosting for Scalable Shared Micro-Mobility Demand Forecasting</title>
      <link>https://arxiv.org/abs/2602.20671v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.20671v1</guid>
      <description>Bikelution is a novel federated learning framework for scalable, privacy-preserving micro-mobility demand forecasting using gradient-boosted decision trees. Unlike centralized ML—which achieves high accuracy but violates data privacy and incurs prohibitive bandwidth costs—Bikelution enables collaborative model training across edge devices (e.g., bike docks, city zones) without sharing raw spatio-temporal data. It introduces sparse histogram-based gradient compression, differential privacy-aware secure aggregation, and a sliding-window client selection strategy to handle non-IID demand patterns. Evaluated on three real-world dockless bike-sharing datasets (Hangzhou, NYC Citi Bike, Singapore SG Bike), Bikelution matches centralized XGBoost’s 6-hour-ahead forecast accuracy (within 2.1% MAE gap) while outperforming state-of-the-art federated tree methods by 19.3% on average. This demonstrates that high-fidelity, mid-term demand forecasting is feasible under strict privacy constraints—enabling sustainable, compliant smart mobility planning.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>learning</category>
      <category>federated</category>
    </item>
    <item>
      <title>Is the Trigger Essential? A Feature-Based Triggerless Backdoor Attack in Vertical Federated Learning</title>
      <link>https://arxiv.org/abs/2602.20593v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.20593v1</guid>
      <description>Vertical federated learning (VFL) enables collaborative modeling across parties holding disjoint features and labels, yet remains vulnerable to backdoor attacks. Contrary to the prevailing trigger-dependent paradigm, this paper demonstrates that **triggers are *not essential* for effective backdoor attacks in VFL**. We propose the first **feature-based triggerless backdoor attack**, operating under a stricter honest-but-curious threat model—where the attacker participates legitimately in training without gradient tampering. Our method comprises three key components: (1) label inference to identify target classes from intermediate outputs; (2) triggerless poisoning via feature amplification and imperceptible perturbation; and (3) stealthy backdoor execution on *clean, unmodified inputs*. Experiments on five benchmark datasets show our attack achieves 2–50× higher attack success rate (ASR) than three trigger-based baselines, with &lt;0.8% main-task accuracy degradation. It remains highly effective even in large-scale VFL (32 passive parties) using only one auxiliary dataset and exhibits strong resilience against defenses (ASR variation &lt;3%). This work uncovers a critical blind spot in VFL security and calls for robust, trigger-agnostic defense design.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>inference</category>
      <category>learning</category>
      <category>security</category>
      <category>train</category>
      <category>privacy-preserving</category>
    </item>
    <item>
      <title>Characterizing Online and Private Learnability under Distributional Constraints via Generalized Smoothness</title>
      <link>https://arxiv.org/abs/2602.20585v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.20585v1</guid>
      <description>This paper characterizes online and private learnability under *distributional adversaries*—adaptive sequences of data-generating distributions drawn from a fixed family $U$. We introduce **generalized smoothness**, a structural property of $U$, and prove it is *necessary and sufficient* for online learnability: a family $U$ admits VC-dimension-dependent regret bounds for *every* finite-VC hypothesis class if and only if $U$ is generalized smooth. We design universal algorithms achieving low regret without explicit knowledge of $U$, and—when $U$ is known—derive refined bounds via the **fragmentation number**, a combinatorial measure of how many disjoint regions can simultaneously carry nontrivial mass under $U$. Remarkably, we show generalized smoothness also *exactly characterizes* private learnability under distributional constraints, revealing a deep unification between online and differentially private learning. These results provide a near-complete theory of learnability beyond i.i.d. and fully adversarial settings.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>privacy</category>
      <category>differential</category>
    </item>
    <item>
      <title>Wireless Federated Multi-Task LLM Fine-Tuning via Sparse-and-Orthogonal LoRA</title>
      <link>https://arxiv.org/abs/2602.20492v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.20492v1</guid>
      <description>This paper proposes **Sparse-and-Orthogonal LoRA**, a fully decentralized wireless federated learning framework for multi-task fine-tuning of large language models (LLMs) on mobile devices. It tackles three critical issues in heterogeneous edge settings: (i) catastrophic forgetting during local fine-tuning due to conflicting gradient directions; (ii) inefficient communication and slow convergence from redundant parameter transmission; and (iii) cross-task knowledge interference at inference. Our approach introduces: (1) orthogonality-constrained sparse LoRA adapters to eliminate update conflicts; (2) a task-aware clustering strategy for topology-efficient model aggregation among neighboring devices; and (3) an implicit mixture-of-experts mechanism enabling task-specific inference paths without explicit routing. Experiments show up to **73% reduction in communication cost** and **+5.0% average accuracy gain** over standard federated LoRA, with faster convergence—demonstrating strong practicality for bandwidth-constrained wireless edge AI.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>learning</category>
      <category>federated</category>
    </item>
    <item>
      <title>Heterogeneity-Aware Client Selection Methodology For Efficient Federated Learning</title>
      <link>https://arxiv.org/abs/2602.20450v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.20450v1</guid>
      <description>Federated Learning (FL) suffers from statistical heterogeneity across clients, leading to accuracy degradation and unstable convergence. Prior client selection methods rely on loss or bias—imprecise proxies for heterogeneity—and employ stochastic selection, limiting reliability. We propose **Terraform**, a novel heterogeneity-aware methodology that leverages **client gradient updates** (not scalar metrics) to quantify directional and magnitude deviation from the global gradient, enabling precise heterogeneity assessment. Its **deterministic greedy algorithm** selects the top-*k* most heterogeneous clients per round—ensuring reproducibility and stability. Evaluated across four benchmarks (CIFAR-10/100, Tiny-ImageNet, LEAF-HeartDisease), Terraform achieves up to **47% higher accuracy** over state-of-the-art baselines (e.g., FedAvg, q-FFL). Ablation studies confirm both gradient-based modeling and deterministic selection are essential; training overhead remains under 3% per round. Terraform delivers a robust, efficient, and principled solution for heterogeneous FL.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>learning</category>
      <category>federated</category>
    </item>
    <item>
      <title>Partially Non-Interactive Two-Round Threshold and Multi-Signatures with Tighter and Adaptive Security</title>
      <link>https://eprint.iacr.org/2026/373</link>
      <guid isPermaLink="true">https://eprint.iacr.org/2026/373</guid>
      <description>We bridge a critical security gap in partially non-interactive (PNI) two-round threshold and multi-signature schemes in the pairing-free discrete-logarithm setting. While fully online schemes achieve rewinding-free or fully adaptive security under standard assumptions, prior PNI schemes require algebraic adversary restrictions or non-standard assumptions. Our key insight is to systematically transform the HBMS framework (Bellare &amp; Dai, Asiacrypt 2021) into a PNI paradigm via message-independent preprocessing of commitments and adaptive key derivation. We present: (1) the **first PNI two-round multi-signature scheme** with a rewinding-free reduction under standard DL assumptions, achieving tighter security (O(1) loss) against *non-algebraic* adversaries; and (2) the **first PNI two-round threshold signature scheme** with *fully adaptive security*—supporting adaptive corruptions and message queries—also under standard assumptions. Both schemes retain practical efficiency and avoid random oracles.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>IACR</category>
    </item>
    <item>
      <title>"Are You Sure?": An Empirical Study of Human Perception Vulnerability in LLM-Driven Agentic Systems</title>
      <link>https://arxiv.org/abs/2602.21127v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.21127v1</guid>
      <description>Large language model (LLM) agents are increasingly trusted in high-stakes domains, yet this trust introduces a novel human-centered threat: Agent-Mediated Deception (AMD), where compromised agents subtly mislead users. This paper presents the first large-scale empirical study of human susceptibility to AMD, involving 303 participants using our high-fidelity research platform, HAT-Lab, featuring nine realistic scenarios across healthcare, software development, and HR. Key findings include: only 8.6% of participants detected AMD attacks; domain experts showed *increased* vulnerability in certain contexts; six recurrent cognitive failure modes were identified; and risk awareness rarely translated into protective behavior. Critically, low-cost, workflow-integrated warnings significantly improved detection, and brief experiential training in HAT-Lab increased user caution against AMD by over 90%. This work establishes foundational empirical evidence and an open platform for human-centric agent security.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>llm</category>
      <category>agent</category>
      <category>security</category>
    </item>
    <item>
      <title>SoK: Agentic Skills -- Beyond Tool Use in LLM Agents</title>
      <link>https://arxiv.org/abs/2602.20867v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.20867v1</guid>
      <description>This SoK paper establishes *agentic skills*—reusable, condition-aware procedural modules—as a foundational layer beyond atomic tool use in LLM agents. We map their full lifecycle (discovery, practice, distillation, storage, composition, evaluation, update) and introduce two complementary taxonomies: (1) **seven system-level design patterns**, ranging from metadata-driven progressive disclosure to self-evolving libraries and marketplace distribution; and (2) an orthogonal **representation × scope taxonomy**, classifying skills by *what they are* (NL/code/policy/hybrid) and *where they operate* (web/OS/SE/robotics). Security analysis, grounded in the ClawHavoc campaign (1,200+ malicious skills exfiltrating API keys, crypto wallets, and credentials), exposes critical supply-chain risks, prompt injection via skill payloads, and the need for trust-tiered execution. Benchmark evidence shows curated skills boost agent success rates substantially (+38%), while unverified self-generated skills degrade performance (−22%). We conclude with open challenges toward robust, verifiable, and certifiable skills for real-world autonomy.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>security</category>
      <category>injection</category>
      <category>agent</category>
      <category>llm</category>
      <category>prompt</category>
    </item>
    <item>
      <title>AdapTools: Adaptive Tool-based Indirect Prompt Injection Attacks on Agentic LLMs</title>
      <link>https://arxiv.org/abs/2602.20720v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.20720v1</guid>
      <description>AdapTools is a novel adaptive tool-based framework for indirect prompt injection (IPI) attacks targeting agentic LLMs—systems that leverage external tools (e.g., MCP) for complex task execution. Unlike prior static IPI methods, AdapTools dynamically selects stealthy, defense-evading tools and generates context-aware adversarial prompts via transferable adversarial strategy optimization. Evaluated across six state-of-the-art agent architectures (including Llama-3-Agentic and Claude-3.5-Opus-Agent), it achieves a **2.13× improvement in attack success rate** (69.8% vs. 32.7%) while degrading system utility by only **1.78×**, demonstrating strong efficacy–utility trade-off balance. Crucially, AdapTools maintains &gt;61% success against advanced defenses like RAGGuard and ToolShield. This work advances IPI understanding and provides the first adaptive, tool-aware benchmark for evaluating agent security.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>injection</category>
      <category>prompt</category>
    </item>
    <item>
      <title>PackMonitor: Enabling Zero Package Hallucinations Through Decoding-Time Monitoring</title>
      <link>https://arxiv.org/abs/2602.20717v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.20717v1</guid>
      <description>Large Language Models (LLMs) frequently hallucinate non-existent software packages during dependency recommendation—a critical reliability and security risk. While prior work reduces hallucination rates, none eliminates them. We establish that package validity is *decidable* via finite, authoritative registries (e.g., PyPI, npm), enabling theoretical zero-hallucination guarantees. PackMonitor is the first decoding-time monitoring framework achieving this: it dynamically constrains token generation to real packages only, without model retraining or fine-tuning. It introduces (1) a Context-Aware Parser that triggers intervention *only* during installation command generation; (2) a Package-Name Intervenor that enforces strict vocabulary restriction to live registry entries; and (3) a DFA-Caching Mechanism for sub-millisecond, memory-efficient matching over &gt;2M packages. Evaluated on five widely used LLMs, PackMonitor achieves **0% package hallucination** consistently, preserves original model capabilities, adds &lt;8% latency overhead, and requires zero training—delivering a plug-and-play solution for trustworthy software AI.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>inference</category>
      <category>security</category>
    </item>
    <item>
      <title>ICON: Indirect Prompt Injection Defense for Agents based on Inference-Time Correction</title>
      <link>https://arxiv.org/abs/2602.20708v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.20708v1</guid>
      <description>Large Language Model (LLM) agents are vulnerable to Indirect Prompt Injection (IPI) attacks, where malicious instructions embedded in retrieved content hijack agent behavior. Existing defenses rely heavily on filtering or refusal—often causing *over-refusal* and breaking legitimate workflows. We propose **ICON**, an inference-time correction framework that detects and mitigates IPI *without interrupting task execution*. ICON introduces a **Latent Space Trace Prober** that identifies IPI via distinctive over-focusing signatures in attention activations, achieving a competitive 0.4% Attack Success Rate (ASR)—on par with commercial detectors. Its **Mitigating Rectifier** then performs surgical attention steering: suppressing adversarial query-key dependencies while amplifying task-relevant ones. Evaluated across Llama-3, Qwen2, and Phi-3, ICON boosts task utility by &gt;50% over baselines while maintaining robust OOD generalization and extending seamlessly to multimodal agents—setting a new standard for secure, efficient agentic systems.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>inference</category>
      <category>security</category>
      <category>injection</category>
      <category>agent</category>
      <category>llm</category>
    </item>
    <item>
      <title>ICSSPulse: A Modular LLM-Assisted Platform for Industrial Control System Penetration Testing</title>
      <link>https://arxiv.org/abs/2602.20663v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.20663v1</guid>
      <description>ICSSPulse is the first open-source, web-based, modular platform unifying network scanning, protocol-aware Modbus and OPC UA interaction, and LLM-assisted reporting for Industrial Control System (ICS) penetration testing. Designed to address safety and reproducibility challenges in real-world ICS environments, it provides a lightweight graphical interface orchestrating enumeration, exploitation, and reporting over simulated industrial services—while preserving strict protocol fidelity and operational transparency. Experimental evaluation across synthetic Modbus servers, a Factory I/O water treatment scenario, and a custom OPC UA production-line model confirmed its capability to reliably discover active ICS services, enumerate process-critical assets (e.g., 23 valves/tanks), and manipulate live process variables. Crucially, its integrated LLM module automatically generates structured executive and technical reports—including risk-ranked mitigation guidance grounded in the MITRE ATT&amp;CK® ICS framework—bridging the gap between raw findings and actionable security intelligence.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>llm</category>
      <category>security</category>
    </item>
    <item>
      <title>Understanding Human-AI Collaboration in Cybersecurity Competitions</title>
      <link>https://arxiv.org/abs/2602.20446v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.20446v1</guid>
      <description>This paper presents the first empirical study of human-AI collaboration in a live, onsite Capture-the-Flag (CTF) competition with 41 participants across 13 teams. We instrumented an AI assistant to support real-time security tasks and collected rich behavioral, interaction, and survey data to examine: (i) how participants’ perceptions, trust, and expectations evolved before versus after hands-on use; (ii) how they dynamically delegated subtasks to the AI during solving; and (iii) how their performance compared against four state-of-the-art autonomous AI agents benchmarked on the *same fresh challenge set*. Key findings reveal that collaboration deepens over time—teams progressively grant AI greater agency—but human limitations in prompting and context specification—not model reasoning—become the dominant bottleneck. Crucially, autonomous agents capable of self-directed prompting and tool orchestration bypass this bottleneck entirely: one ranked **2nd overall**, outperforming 85% of human teams. These results underscore that effective human-in-the-loop cybersecurity systems must prioritize context-aware assistance and transparent delegation—not just raw AI capability.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>agent</category>
      <category>security</category>
    </item>
    <item>
      <title>WOTS-Tree: Merkle-Optimized Winternitz Signatures for Post-Quantum Bitcoin</title>
      <link>https://eprint.iacr.org/2026/374</link>
      <guid isPermaLink="true">https://eprint.iacr.org/2026/374</guid>
      <description>We introduce **WOTS-Tree**, a stateful hash-based signature scheme for Bitcoin that integrates WOTS+ one-time signatures with a binary Merkle tree, enabling up to $2^{21}$ signatures per address. Optimized for Bitcoin’s UTXO model, it adopts a dual-hash design: 128-bit truncated SHA-256 ($n=16$, $w=256$) for efficient WOTS+ chain evaluation, and full 256-bit SHA-256 for Merkle compression. Deployed as dual leaves in BIP-341 Taproot (and compatible with BIP-360), its hardened default mode offers a 353-byte witness for single-use UTXOs and a 675-byte fallback Merkle path ($K=1{,}024$) for RBF/reuse. For Lightning, $K=2^{21}$ yields 1,028-byte witnesses with a one-time 19-second setup. A compact opt-in mode reduces witnesses to 515–692 bytes at ≈60-bit Merkle binding security. Verification is bounded at 4,601 hashes (≈0.009 ms on SHA-NI), achieving 115.8-bit classical / 57.9-bit quantum forgery resistance—exceeding WOTS+ bounds—and ≈124-bit Merkle binding. WOTS-Tree witnesses are 4–7× smaller than hypertree variants while aligning natively with Bitcoin’s spend-once semantics.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>IACR</category>
    </item>
    <item>
      <title>Pairing-based Functional Commitments for Circuits with Shorter Parameters</title>
      <link>https://eprint.iacr.org/2026/379</link>
      <guid isPermaLink="true">https://eprint.iacr.org/2026/379</guid>
      <description>We present the first pairing-based functional commitment (FC) for circuits with *significantly shorter public parameters*. For bounded-width $w$ circuits of unbounded depth $d$, our scheme achieves $O(\lambda w^3)$ public parameter size—improving over the prior $O(\lambda w^5)$ bound (BCFL, TCC’23) by two orders. It retains all desirable properties: $O(\lambda)$-sized commitments, $O(\lambda d^2)$-sized proofs, additive homomorphism, efficient verification, and chainability. For bounded-size $s$ circuits, we alternatively achieve $O(\lambda s^3)$ public parameters with $O(\lambda d)$-sized proofs. At its core lies a novel *chainable FC for quadratic functions*, where commitments are computed w.r.t. a *power basis*, combined with new *basis-switching techniques* enabling efficient transitions between commitment representations. This work bridges a critical efficiency gap in algebraic FCs and advances practical deployment of succinct argument systems.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>IACR</category>
    </item>
    <item>
      <title>Information-Theoretic Network-Agnostic MPC with Polynomial Communication</title>
      <link>https://eprint.iacr.org/2026/378</link>
      <guid isPermaLink="true">https://eprint.iacr.org/2026/378</guid>
      <description>Network-agnostic MPC simultaneously tolerates up to $t_s &lt; n/2$ corruptions in synchronous networks and $t_a &lt; n/3$ in asynchronous networks, achieving optimal resilience under the condition $2t_s + t_a &lt; n$. Prior to this work, no information-theoretic protocol achieved polynomial communication under this resilience; computational protocols (without FHE) incurred $O(n^2)$ field elements per multiplication gate. We introduce the **first information-theoretic network-agnostic MPC** with **quadratic communication ($O(n^2)$ per multiplication)**, relying solely on secret sharing and error-correcting codes. Furthermore, we present the **first computational protocol with linear communication ($O(n)$ per multiplication)**, built exclusively from digital signatures and symmetric-key encryption—no public-key primitives, zero-knowledge proofs, or trusted setup are required. These results significantly advance the efficiency frontier for robust, model-agnostic secure computation.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>IACR</category>
    </item>
    <item>
      <title>Perfectly Secure Network-Agnostic MPC Comes for Free</title>
      <link>https://eprint.iacr.org/2026/377</link>
      <guid isPermaLink="true">https://eprint.iacr.org/2026/377</guid>
      <description>Secure multiparty computation (MPC) enables parties to jointly evaluate a function on private inputs. Classical protocols assume either synchronous or asynchronous networks—trading off resilience against corruptions for timing assumptions. The network-agnostic model removes this assumption: a single protocol must be *perfectly secure* under *both* models, tolerating up to $t_s$ corruptions synchronously and $t_a$ asynchronously, with optimal threshold $n = 2\max(t_s, t_a) + \max(2t_a, t_s) + 1$. Prior works either miss this bound or incur exponential cost. We present the **first perfectly secure network-agnostic MPC protocol achieving the optimal threshold with polynomial communication and computation**. Our key technical contribution is a black-box compiler that composes synchronous and asynchronous Beaver triple generation protocols, requiring only $\mathcal{O}(n^2)$ instances of network-agnostic Byzantine agreement beyond the base protocols. For an arithmetic circuit $C$ over field $\mathbb{F}$ ($|\mathbb{F}| = \mathcal{O}(n)$), depth $D$, and input size $C_I$, the expected communication is $\mathcal{O}\big((|C|n + (D+C_I)n^2 + n^6)\log n\big)$ bits.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>IACR</category>
    </item>
    <item>
      <title>Is PSI Really Faster Than PSU? Achieving Efficient PSU with Invertible Bloom Filters</title>
      <link>https://eprint.iacr.org/2026/376</link>
      <guid isPermaLink="true">https://eprint.iacr.org/2026/376</guid>
      <description>Private Set Union (PSU) allows two parties to compute the union of their private sets without revealing any element outside the union—yet existing PSU protocols lag behind PSI by up to 30× in practice. This paper introduces the **first IBLT-based PSU protocol**, establishing a novel structural framework grounded in *union peelability*: we show that union elements can be recovered *directly* from each party’s individual IBLTs—without constructing a combined IBLT—by exploiting inherent algebraic invariants. Security is achieved using only lightweight primitives: Oblivious Transfer (OT) and Oblivious Pseudorandom Functions (OPRF) for equality checks, leaking nothing beyond the union. Our protocol achieves **0.08–2.95 seconds** for set sizes $2^{14}$–$2^{20}$ in LAN—matching state-of-the-art PSI—and outperforms prior PSU works by up to **10× in LAN** and consistently in WAN, all with linear ($O(n)$) communication and computation complexity and small constants.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>IACR</category>
    </item>
    <item>
      <title>Liquid Democracy With Two Opposing Factions</title>
      <link>https://eprint.iacr.org/2026/375</link>
      <guid isPermaLink="true">https://eprint.iacr.org/2026/375</guid>
      <description>This paper studies liquid democracy in a realistic, adversarial setting with two opposing factions and no ground truth—contrasting prior work focused on truth-aggregation. We model $n$ voters with binary preferences $\{0,1\}$, partitioned into factions; the goal is for each faction to jointly design delegation strategies maximizing its win probability. Under *incomplete information* (e.g., only partial knowledge of the opponent’s size or preference distribution), we propose a practical, low-communication distributed algorithm yielding approximately optimal delegation. With *complete information* about the opponent, we provide a full analytical characterization: optimal strategies must form “cohesive hierarchical delegations” toward high-influence nodes within the faction, and we derive closed-form win probabilities. Finally, we prove that computing optimal delegation in the general adversarial, sequential setting is **PSPACE-complete**, establishing fundamental computational hardness. These results bridge theory and practice for liquid democracy in competitive environments.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>IACR</category>
    </item>
    <item>
      <title>Adversarial Intent is a Latent Variable: Stateful Trust Inference for Securing Multimodal Agentic RAG</title>
      <link>https://arxiv.org/abs/2602.21447v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.21447v1</guid>
      <description>This paper identifies a critical gap in multimodal agentic RAG security: stateless defenses fail against adversarial strategies that *distribute malicious semantics across retrieval, planning, and generation stages*. We formalize the problem as a Partially Observable Markov Decision Process (POMDP), treating adversarial intent as a latent variable inferred from noisy, multi-stage observations. To address this, we propose **MMA-RAG&lt;sup&gt;T&lt;/sup&gt;**, an inference-time, model-agnostic control framework governed by a Modular Trust Agent (MTA) that maintains an approximate belief state via structured LLM reasoning. MMA-RAG&lt;sup&gt;T&lt;/sup&gt; enforces stateful, defense-in-depth through configurable internal checkpoints. Evaluated on 43,774 instances, it achieves a **6.50× average reduction in Attack Success Rate** versus undefended baselines, with negligible utility cost (−0.32% task accuracy). Crucially, factorial ablation confirms theoretical necessity: statefulness (+26.4 pp gain) and spatial coverage (+13.6 pp) are individually indispensable; stateless multi-point intervention yields zero marginal benefit under perfectly correlated checkpoint detections.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>inference</category>
      <category>security</category>
      <category>llm</category>
      <category>agent</category>
    </item>
    <item>
      <title>FedVG: Gradient-Guided Aggregation for Enhanced Federated Learning</title>
      <link>https://arxiv.org/abs/2602.21399v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.21399v1</guid>
      <description>Federated Learning (FL) enables collaborative model training without raw data sharing, yet severe performance degradation arises from client drift under data heterogeneity—exacerbated by naive aggregation favoring poorly generalizing clients. To address this, we propose **FedVG**, a novel gradient-guided aggregation framework that leverages a *small, public global validation set* (e.g., ImageNet subsets or CheXpert samples) to steer optimization while preserving privacy. Unlike volume-based weighting, FedVG computes **layerwise gradient norms** on the validation set to derive a client-specific *Generalization Calibration Score*, quantifying each client’s need for adjustment toward better global generalization. This enables adaptive, generalization-aware aggregation. Extensive experiments across natural (CIFAR, Tiny-ImageNet) and medical (CheXpert, Retina) benchmarks—with CNNs, ViTs, and MobileNets—show FedVG consistently improves accuracy by **2.3–5.7%** under high heterogeneity (Dirichlet α=0.1), outperforming FedAvg, FedProx, and SCAFFOLD. Crucially, it is modular: integrating with state-of-the-art FL algorithms (e.g., FedNova, MOON) yields further gains of **1.1–2.4%**. Code: https://github.com/alinadevkota/FedVG.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>learning</category>
      <category>federated</category>
    </item>
    <item>
      <title>Small Language Models for Privacy-Preserving Clinical Information Extraction in Low-Resource Languages</title>
      <link>https://arxiv.org/abs/2602.21374v1</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.21374v1</guid>
      <description>This study introduces a privacy-preserving, fine-tuning-free pipeline for clinical information extraction from low-resource language transcripts. Using 1,221 anonymized Persian palliative care call transcripts, we first translate them to English via Aya-expanse-8B, then apply five open-source small language models (SLMs)—Qwen2.5-7B-Instruct, Llama-3.1-8B-Instruct, Llama-3.2-3B-Instruct, Qwen2.5-1.5B-Instruct, and Gemma-3-1B-it—in a few-shot prompting setup to extract 13 binary clinical features. Evaluation metrics account for class imbalance: macro-F1, Matthews Correlation Coefficient (MCC), sensitivity, and specificity. Qwen2.5-7B-Instruct achieved the best overall performance (median macro-F1 = 0.899; MCC = 0.797), while larger SLMs (7B–8B) consistently outperformed smaller ones in sensitivity and MCC. Translation improved sensitivity and robustness to imbalance but slightly reduced specificity. Physiological symptoms were reliably extracted; psychological, administrative, and complex somatic features remained challenging. This work establishes a practical, infrastructure-light blueprint for multilingual clinical NLP in resource-constrained settings.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>model</category>
      <category>extraction</category>
    </item>
    <item>
      <title>Some Simple Economics of AGI</title>
      <link>https://arxiv.org/abs/2602.20946v2</link>
      <guid isPermaLink="true">https://arxiv.org/abs/2602.20946v2</guid>
      <description>This paper reframes the AGI transition through a structural economic lens: while the marginal cost of *execution* for measurable tasks collapses toward zero, the marginal cost of *human verification*—auditing, validating, and underwriting responsibility—remains biologically constrained. We model this as a collision between an exponentially decaying Cost-to-Automate curve and a rigid, bandwidth-limited Cost-to-Verify curve, generating a widening Measurability Gap. This asymmetry drives a shift from skill-biased to *measurability-biased* technical change, reallocating rents toward verification-grade ground truth, cryptographic provenance, and liability underwriting. The current human-in-the-loop equilibrium is unstable—eroded from below by collapsing apprenticeship (“Missing Junior Loop”) and from within by expert self-codification (“Codifier’s Curse”). Unverified deployment becomes privately rational yet socially hazardous, risking a Hollow Economy. Crucially, scaling verification capacity *alongside* agentic capability transforms this threat into the foundation for an Augmented Economy. The central policy imperative is not racing to deploy autonomy—but racing to secure the infrastructure of oversight.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>arXiv</category>
      <category>ai</category>
      <category>trojan</category>
    </item>
    <item>
      <title>The Structured Generic-Group Model</title>
      <link>https://eprint.iacr.org/2026/384</link>
      <guid isPermaLink="true">https://eprint.iacr.org/2026/384</guid>
      <description>This paper introduces the **Structured Generic-Group Model (SGGM)**, a rigorous extension of Shoup’s generic-group model that captures algorithms exploiting *partial non-generic structure*—e.g., multiplicative properties of smooth integers—while remaining generic on most group elements. We formalize “structure exploitation” as access to non-black-box operations on at most a $\delta$ fraction of group elements. Our main theorem proves that any discrete-log algorithm in a prime-order group $q$ using structure of at most $\delta$ fraction of elements requires $\Omega(\min(\sqrt{q},\,1/\delta))$ time—a tight lower bound. As a key application, we establish a **tight subexponential lower bound** for index-calculus–style algorithms that leverage smooth integer structure but are otherwise generic; this applies broadly to algorithms exploiting small integers, smooth polynomials, and structured elliptic-curve points. The SGGM bridges the gap between idealized generic models and real-world structural attacks.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>IACR</category>
    </item>
    <item>
      <title>HCTR$^{++}$ : A Beyond Birthday Bound Secure HCTR2 Variant</title>
      <link>https://eprint.iacr.org/2026/383</link>
      <guid isPermaLink="true">https://eprint.iacr.org/2026/383</guid>
      <description>Current industry-standard block cipher modes (e.g., CBC, GCM) suffer from the birthday-bound security limit $O(2^{n/2})$, now a practical bottleneck in high-throughput systems. To address this, NIST’s Accordion Mode project defines the **Tweakable Variable-Input-Length Strong Pseudorandom Permutation (VIL-SPRP)**—a new primitive requiring Beyond Birthday Bound (BBB) security, i.e., $O(q^2/2^n)$ advantage for $q$ queries. We propose **HCTR$^{++}$**, a simple, efficient, and provably secure BBB variant of HCTR2. Unlike prior BBB constructions relying on Tweakable Block Ciphers (TBCs) or fresh rekeying, HCTR$^{++}$ builds solely on standard block ciphers (e.g., AES), introduces an enhanced tweak derivation and dual-key schedule, and maintains full parallelism and low latency. Its security is formally proven in the ideal cipher model, achieving optimal BBB security while remaining hardware-friendly and compatible with existing HCTR2 implementations. HCTR$^{++}$ serves as a concrete, standardized-ready candidate for the VIL-SPRP framework.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>IACR</category>
    </item>
    <item>
      <title>Multi-key Security in the Quantum World: Revisiting Tweakable Even-Mansour and FX</title>
      <link>https://eprint.iacr.org/2026/382</link>
      <guid isPermaLink="true">https://eprint.iacr.org/2026/382</guid>
      <description>This paper establishes the first multi-key security proofs for two fundamental symmetric-key constructions—the tweakable Even-Mansour cipher (TEM) and the FX construction—in the Q1MK model, which combines classical online queries, quantum offline queries (Q1), and multiple independent keys. Using a refined hybrid argument technique (Alagic et al., EUROCRYPT 2022), we prove that breaking TEM requires $\Omega(2^{\kappa/3})$ classical and quantum queries—*independent of the number of $\kappa$-bit keys*. For FX with a $(\kappa+n)$-bit key, we tighten its Q1-security bound from prior work to $\Omega(2^{(\kappa+n)/3})$, then extend it to Q1MK: breaking FX with $2^u$ ($u \le \kappa$) distinct keys demands $\Omega(2^{(\kappa+n-u)/3})$ queries—demonstrating a quantifiable *security gain from key diversity*. These results provide foundational guarantees for post-quantum symmetric cryptography in realistic multi-user deployments.</description>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0000</pubDate>
      <category>IACR</category>
    </item>
  </channel>
</rss>