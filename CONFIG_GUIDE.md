# é…ç½®æŒ‡å— (Configuration Guide)

æœ¬é¡¹ç›®ä½¿ç”¨ `config.toml` è¿›è¡Œé…ç½®ç®¡ç†ã€‚ä½ å¯ä»¥é€šè¿‡ä¿®æ”¹æ­¤æ–‡ä»¶æ¥è‡ªå®šä¹‰å„ç§è¡Œä¸ºã€‚

## é…ç½®æ–‡ä»¶ä½ç½®

`config.toml` ä½äºé¡¹ç›®æ ¹ç›®å½•ã€‚

## é…ç½®é¡¹è¯´æ˜

### 1. é€šç”¨è®¾ç½® (`[general]`)

```toml
[general]
# ä¿ç•™è®ºæ–‡çš„å¤©æ•°ï¼ˆä¹Ÿæ˜¯ç¼“å­˜ summary çš„æ—¶é—´ï¼‰
days_back = 7

# æ•°æ®å­˜å‚¨è·¯å¾„
data_dir = "data"
papers_file = "papers.json"
failed_file = "failed.json"
```

**è¯´æ˜ï¼š**
- `days_back`: è¶…è¿‡è¿™ä¸ªå¤©æ•°çš„è®ºæ–‡ä¼šè¢«è‡ªåŠ¨åˆ é™¤ï¼ŒåŒæ—¶ä¹Ÿå†³å®šäº†ä» arXiv/IACR æŠ“å–å¤šå°‘å¤©å†…çš„è®ºæ–‡
- ä¿®æ”¹ä¸º 30 å¯ä»¥ä¿ç•™ä¸€ä¸ªæœˆçš„è®ºæ–‡è®°å½•

### 2. arXiv æŠ“å–è®¾ç½® (`[fetchers.arxiv]`)

```toml
[fetchers.arxiv]
# è¦æŠ“å–çš„ arXiv åˆ†ç±»
categories = ["cs.CR", "cs.AI", "cs.LG", "cs.CL"]

# è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰- arXiv å»ºè®® 3 ç§’ä»¥ä¸Š
delay = 3.0

# æ¯ä¸ªåˆ†ç±»æœ€å¤šæŠ“å–çš„è®ºæ–‡æ•°
max_results = 500

# æ¯æ¬¡è¯·æ±‚è¿”å›çš„è®ºæ–‡æ•°
batch_size = 100
```

**å¸¸ç”¨ arXiv åˆ†ç±»ï¼š**
- `cs.CR` - Cryptography and Securityï¼ˆå¯†ç å­¦ä¸å®‰å…¨ï¼‰
- `cs.AI` - Artificial Intelligenceï¼ˆäººå·¥æ™ºèƒ½ï¼‰
- `cs.LG` - Machine Learningï¼ˆæœºå™¨å­¦ä¹ ï¼‰
- `cs.CL` - Computation and Languageï¼ˆNLPï¼‰
- `cs.CV` - Computer Visionï¼ˆè®¡ç®—æœºè§†è§‰ï¼‰
- `stat.ML` - Machine Learning (Statistics)

### 3. IACR æŠ“å–è®¾ç½® (`[fetchers.iacr]`)

```toml
[fetchers.iacr]
# è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
delay = 2.0
```

### 4. AI æ‘˜è¦ç”Ÿæˆè®¾ç½® (`[summarizer]`)

```toml
[summarizer]
# ä½¿ç”¨çš„æ¨¡å‹
model = "qwen-plus"

# æœ€å¤§ç”Ÿæˆ token æ•°
max_tokens = 500

# æ¸©åº¦å‚æ•°ï¼ˆ0-1ï¼Œè¶Šé«˜è¶Šéšæœºï¼‰
temperature = 0.7

# API è¯·æ±‚è¶…æ—¶ï¼ˆç§’ï¼‰
timeout = 60

# API è°ƒç”¨é—´éš”ï¼ˆç§’ï¼‰
rate_limit_delay = 1.0

# å¤±è´¥é‡è¯•æ¬¡æ•°
max_retries = 3

# é‡è¯•é—´éš”ï¼ˆç§’ï¼‰
retry_delay = 5.0
```

**å¯ç”¨æ¨¡å‹ï¼š**
- `qwen-turbo` - æœ€å¿«ï¼Œé€‚åˆç®€å•ä»»åŠ¡
- `qwen-plus` - å¹³è¡¡æ€§èƒ½å’Œè´¨é‡ï¼ˆé»˜è®¤ï¼‰
- `qwen-max` - æœ€å¼ºæ€§èƒ½ï¼Œä½†æ›´æ…¢æ›´è´µ

### 5. åŒè¯­æ‘˜è¦æ”¯æŒ ğŸ†•

**é‡è¦æ›´æ–°ï¼š** ç³»ç»Ÿç°åœ¨è‡ªåŠ¨ç”Ÿæˆ**ä¸­è‹±æ–‡åŒè¯­æ‘˜è¦**ï¼

- âœ… UI é»˜è®¤æ˜¾ç¤º**ä¸­æ–‡æ‘˜è¦**
- âœ… å¯é€šè¿‡ä¸‹æ‹‰èœå•åˆ‡æ¢åˆ°**è‹±æ–‡æ‘˜è¦**
- âœ… åŒè¯­æ‘˜è¦éƒ½æ”¯æŒ Markdown æ ¼å¼
- âœ… æ•°æ®æ–‡ä»¶ä¸­åŒ…å« `summary_zh` å’Œ `summary_en` ä¸¤ä¸ªå­—æ®µ

**åŒè¯­ Prompt ä¿®æ”¹ï¼š**

åŒè¯­ prompt åœ¨ `scripts/summarizer.py` çš„ `_create_bilingual_prompt()` æ–¹æ³•ä¸­å®šä¹‰ï¼Œä»¥ç¡®ä¿ç¨³å®šçš„æ ¼å¼è§£æã€‚å¦‚éœ€ä¿®æ”¹åŒè¯­æ‘˜è¦çš„é£æ ¼ï¼Œè¯·ç›´æ¥ç¼–è¾‘è¯¥æ–‡ä»¶ã€‚

### 6. è‡ªå®šä¹‰ Prompt (`[summarizer.prompt_template]`)

**æ³¨æ„ï¼š** `config.toml` ä¸­çš„ `prompt_template` ç°åœ¨ä¸»è¦ç”¨äºå‘åå…¼å®¹ã€‚å®é™…ä½¿ç”¨çš„æ˜¯åŒè¯­ promptã€‚

**é»˜è®¤åŒè¯­ Promptï¼ˆåœ¨ä»£ç ä¸­ï¼‰ï¼š**
- ä¸­æ–‡æ‘˜è¦ï¼šè¯¦ç»†è§£è¯»è®ºæ–‡çš„èƒŒæ™¯ã€æ–¹æ³•ã€ä¸»è¦å‘ç°å’Œåˆ›æ–°ç‚¹
- è‹±æ–‡æ‘˜è¦ï¼šç®€æ´æ¦‚æ‹¬è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®å’Œå…³é”®ç»“æœï¼ˆ3-5å¥è¯ï¼‰
- ä¸¥æ ¼éµå¾ª `[ä¸­æ–‡æ‘˜è¦]` å’Œ `[English Summary]` æ ‡è®°åˆ†éš”

**å•è¯­ Prompt é…ç½®ï¼ˆå¤‡ç”¨ï¼‰ï¼š**
```toml
prompt_template = """ä½ æ˜¯ä¸€ä½ç²¾é€šå„é¢†åŸŸå‰æ²¿ç ”ç©¶çš„å­¦æœ¯æ–‡çŒ®è§£è¯»ä¸“å®¶ï¼Œé¢å¯¹ä¸€ç¯‡ç»™å®šçš„è®ºæ–‡ï¼Œè¯·ä½ é«˜æ•ˆé˜…è¯»å¹¶è¿…é€Ÿæå–å‡ºå…¶æ ¸å¿ƒå†…å®¹ã€‚è¦æ±‚åœ¨è§£è¯»è¿‡ç¨‹ä¸­ï¼Œå…ˆå¯¹æ–‡çŒ®çš„èƒŒæ™¯ã€ç ”ç©¶ç›®çš„å’Œé—®é¢˜è¿›è¡Œç®€æ˜æ¦‚è¿°ï¼Œå†è¯¦ç»†æ¢³ç†ç ”ç©¶æ–¹æ³•ã€å…³é”®æ•°æ®ã€ä¸»è¦å‘ç°åŠç»“è®ºï¼ŒåŒæ—¶å¯¹æ–°é¢–æ¦‚å¿µè¿›è¡Œé€šä¿—æ˜“æ‡‚çš„è§£é‡Šï¼Œå¸®åŠ©è¯»è€…ç†è§£è®ºæ–‡çš„é€»è¾‘ä¸åˆ›æ–°ç‚¹ï¼›æœ€åï¼Œè¯·å¯¹æ–‡çŒ®çš„ä¼˜ç¼ºç‚¹è¿›è¡Œå®¢è§‚è¯„ä»·ï¼Œå¹¶æŒ‡å‡ºå¯èƒ½çš„åç»­ç ”ç©¶æ–¹å‘ã€‚æ•´ä½“æŠ¥å‘Šç»“æ„æ¸…æ™°ã€é€»è¾‘ä¸¥è°¨ã€‚

Title: {title}

Abstract: {abstract}

Provide a concise summary:"""
```

**ç®€æ´è‹±æ–‡ç‰ˆï¼š**
```toml
prompt_template = """Please summarize this research paper in 3-5 sentences. Focus on the main contribution, methods, and key results.

Title: {title}

Abstract: {abstract}

Provide a concise summary:"""
```

### 7. å…³é”®è¯è¿‡æ»¤ (`[keywords]`)

```toml
[keywords]
# å…³é”®è¯æ–‡ä»¶è·¯å¾„
file = "keywords.txt"
```

**å…³é”®è¯è¯­æ³•ï¼š**
- æ¯è¡Œä¸€ä¸ª OR æ¡ä»¶
- åŒä¸€è¡Œå¤šä¸ªè¯ä¸º AND æ¡ä»¶
- `#` å¼€å¤´ä¸ºæ³¨é‡Š

**ç¤ºä¾‹ (keywords.txt)ï¼š**
```
# åŒ¹é…åŒ…å« "llm" æˆ– "gpt" çš„è®ºæ–‡
llm
gpt

# åŒ¹é…åŒæ—¶åŒ…å« "neural" å’Œ "backdoor" çš„è®ºæ–‡
neural backdoor

# åŒ¹é…è”é‚¦å­¦ä¹ ç›¸å…³è®ºæ–‡
federated learning
```

## å¸¸è§ä½¿ç”¨åœºæ™¯

### åœºæ™¯ 1ï¼šä¿ç•™æ›´é•¿æ—¶é—´çš„è®ºæ–‡

ä¿®æ”¹ `config.toml`ï¼š
```toml
[general]
days_back = 30  # æ”¹ä¸º 30 å¤©
```

### åœºæ™¯ 2ï¼šåªå…³æ³¨å¯†ç å­¦è®ºæ–‡

ä¿®æ”¹ `config.toml`ï¼š
```toml
[fetchers.arxiv]
categories = ["cs.CR"]  # åªä¿ç•™å¯†ç å­¦åˆ†ç±»
```

### åœºæ™¯ 3ï¼šä½¿ç”¨æ›´å¿«çš„æ¨¡å‹

ä¿®æ”¹ `config.toml`ï¼š
```toml
[summarizer]
model = "qwen-turbo"  # ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹
rate_limit_delay = 0.5  # å‡å°‘å»¶è¿Ÿ
```

### åœºæ™¯ 4ï¼šç”Ÿæˆç®€çŸ­æ‘˜è¦

ä¿®æ”¹ `config.toml`ï¼š
```toml
[summarizer]
max_tokens = 200  # é™åˆ¶è¾“å‡ºé•¿åº¦
prompt_template = """Summarize this paper in 1-2 sentences focusing only on the main contribution.

Title: {title}

Abstract: {abstract}

Summary:"""
```

### åœºæ™¯ 5ï¼šä¸­æ–‡è¾“å‡º

ä¿®æ”¹ `config.toml`ï¼š
```toml
[summarizer]
prompt_template = """è¯·ç”¨2-3å¥ä¸­æ–‡æ€»ç»“è¿™ç¯‡è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®ã€‚

æ ‡é¢˜: {title}

æ‘˜è¦: {abstract}

æ€»ç»“ï¼š"""
```

## éªŒè¯é…ç½®

ä¿®æ”¹é…ç½®åï¼Œå¯ä»¥æœ¬åœ°æµ‹è¯•ï¼š

```bash
pip install -r requirements.txt
export DASHSCOPE_API_KEY="your-key"
python scripts/main.py
```

æŸ¥çœ‹ `data/papers.json` ç¡®è®¤æ•ˆæœã€‚

## æ³¨æ„äº‹é¡¹

1. **API é…é¢é™åˆ¶**ï¼šå‡å°‘ `rate_limit_delay` å¯èƒ½å¯¼è‡´è¶…å‡º API é™åˆ¶
2. **arXiv é™åˆ¶**ï¼š`delay` ä¸è¦å°äº 3 ç§’ï¼Œå¦åˆ™å¯èƒ½è¢«å°ç¦
3. **ç¼“å­˜æ—¶é—´**ï¼šä¿®æ”¹ `days_back` ä¸ä¼šå½±å“å·²æœ‰æ•°æ®ï¼Œåªå½±å“æ–°æŠ“å–çš„è®ºæ–‡
4. **Prompt é•¿åº¦**ï¼šè¿‡é•¿çš„ prompt ä¼šæ¶ˆè€—æ›´å¤š tokens
